{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Fetch data from kaggle.\n",
    "2. Prepare data for model training.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "1. Authentication Kaggle JSON file\n",
    "\n",
    "## Outputs\n",
    "\n",
    "1. Image only datasets\n",
    "\n",
    "## Comments\n",
    "\n",
    "Kaggle dataset is already divided in train, validate and test folder. It is important to calculate ratios and redistribute if needed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/OCTreader/jupiter_notebooks\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New working directory: /workspace/OCTreader\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/workspace/OCTreader')\n",
    "print(f'New working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle==1.5.12\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 3.9 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /workspace/.pyenv_mirror/user/3.8.12/lib/python3.8/site-packages (from kaggle==1.5.12) (1.16.0)\n",
      "Requirement already satisfied: certifi in /workspace/.pyenv_mirror/user/3.8.12/lib/python3.8/site-packages (from kaggle==1.5.12) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in /workspace/.pyenv_mirror/user/3.8.12/lib/python3.8/site-packages (from kaggle==1.5.12) (2.9.0)\n",
      "Requirement already satisfied: requests in /workspace/.pyenv_mirror/user/3.8.12/lib/python3.8/site-packages (from kaggle==1.5.12) (2.31.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 5.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting python-slugify\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: urllib3 in /workspace/.pyenv_mirror/user/3.8.12/lib/python3.8/site-packages (from kaggle==1.5.12) (2.2.1)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 8.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /workspace/.pyenv_mirror/user/3.8.12/lib/python3.8/site-packages (from requests->kaggle==1.5.12) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspace/.pyenv_mirror/user/3.8.12/lib/python3.8/site-packages (from requests->kaggle==1.5.12) (3.3.2)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73049 sha256=833c19c84cc8a9ad72ea3c70ea87bf82e2211c38d1b74938aa20c8b8ac824349\n",
      "  Stored in directory: /workspace/.pyenv_mirror/pip_cache/wheels/29/da/11/144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, tqdm, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-8.0.4 text-unidecode-1.3 tqdm-4.66.2\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/gitpod/.pyenv/versions/3.8.12/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install kaggle==1.5.12 package\n",
    "%pip install kaggle==1.5.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring working directory and authentication for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chmod: cannot access 'kaggle.json': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "! chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /workspace/OCTreader/kaggle.json'\n",
      "Downloading kermany2018.zip to inputs/OCTdata\n",
      "100%|█████████████████████████████████████▉| 10.8G/10.8G [05:12<00:00, 35.8MB/s]\n",
      "100%|██████████████████████████████████████| 10.8G/10.8G [05:12<00:00, 37.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Variables containing kaggle data path and local directory to host input data\n",
    "data_path = 'paultimothymooney/kermany2018/data'\n",
    "destination_folder = 'inputs/OCTdata'\n",
    "! kaggle datasets download -d {data_path} -p {destination_folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Find the zip file with kaggle data\n",
    "zip_kaggle_dataset = os.listdir(destination_folder)\n",
    "\n",
    "with zipfile.ZipFile(destination_folder + '/' + zip_kaggle_dataset[0], 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "\n",
    "os.remove(destination_folder + '/' + zip_kaggle_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove redundant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains redundant data that is best to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "data_dir = 'OCT2017 '\n",
    "\n",
    "for current_dir in os.listdir('inputs/OCTdata'):\n",
    "    if current_dir != data_dir:\n",
    "        shutil.rmtree('inputs/OCTdata/' + current_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Split\n",
    "\n",
    "Data is now divided in three folders: train, val and test. Each of these folders contains four folders for the different labels. In this step non-images files are removed and ratios of train, val and test are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def remove_non_images(data_dir):\n",
    "    '''\n",
    "    The function checks data_dir and removes\n",
    "    any files without image extension\n",
    "    and counts image files in folder\n",
    "    '''\n",
    "    image_extensions = ['jpeg', 'png', 'gif']\n",
    "    image_count = 0\n",
    "    for image_file in os.listdir(data_dir):\n",
    "        if image_file.split('.')[1] in image_extensions:\n",
    "            image_count += 1\n",
    "        else:\n",
    "            os.remove(data_dir + image_file)\n",
    "\n",
    "    return image_count\n",
    "\n",
    "\n",
    "def explore_directories(root_dir):\n",
    "    '''\n",
    "    Sweeps all directories calling the non_image removing function\n",
    "    counts the total of images per folder and makes a summary on df    \n",
    "    '''\n",
    "    # empty dataframe\n",
    "    df = pd.DataFrame(columns=['purpose', 'label', 'count'])\n",
    "    labels = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n",
    "    split_dirs = ['train', 'val', 'test']\n",
    "    for split_dir in split_dirs:\n",
    "        for label in labels:\n",
    "            data_dir = root_dir + split_dir + '/' + label\n",
    "            # count per label\n",
    "            count = remove_non_images(data_dir)\n",
    "            # add record of count per directory\n",
    "            df = df.append({'purpose': split_dir, 'label': label, 'count': count}, ignore_index = True)\n",
    "\n",
    "    # create a log plot to observe distribution of images\n",
    "    sns.barplot(data=df, x='label', y='count', hue='purpose')\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "    print('Viasualisation of images distribution across folders')\n",
    "    df_summary = (df.groupby(by=['purpose',]).sum().drop('label', axis=1))\n",
    "    print('Summary of images distribution across folders')\n",
    "    df_summary['ratios'] = df_summary['count']/df_summary['count'].sum()\n",
    "    print(df_summary)\n",
    "    return df_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected ratios are train = 0.7, val = 0.1 and test = 0.2. If this condition is not met, the files need to be redistributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataset(root_dir):\n",
    "    labels = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n",
    "    split_dirs = ['train', 'val', 'test']\n",
    "    os.makedirs(root_dir + '/data')\n",
    "    for label in labels:\n",
    "        os.makedirs(root_dir + '/data/' + label)\n",
    "        for split_dir in split_dirs:\n",
    "            dir_path = root_dir + '/' + split_dir + '/' + label\n",
    "            for image_file in os.listdir(dir_path):\n",
    "                shutil.move(dir_path + '/' + image_file, root_dir + '/data/' + label+ '/' + image_file)\n",
    "\n",
    "combine_dataset('inputs/OCTdata/OCT2017')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>ratios</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>968</td>\n",
       "      <td>0.011458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>83484</td>\n",
       "      <td>0.988163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>32</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count    ratios\n",
       "purpose                 \n",
       "test       968  0.011458\n",
       "train    83484  0.988163\n",
       "val         32  0.000379"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
